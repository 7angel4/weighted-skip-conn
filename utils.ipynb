{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae03426-07f5-46c5-b25f-c482e64de115",
   "metadata": {},
   "source": [
    "# Visualisation\n",
    "\n",
    "We will generate node embeddings, reduce their dimensions, and finally visualsie these embeddings: we expect to empirically observe that the embeddings become more and more similar with more layers.\n",
    "\n",
    "We will use the **validation dataset** for the visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6854a6-d396-4a5f-b3a2-5e9a15f908f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = '/weighted-jk/visuals/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de1dae98-5b08-49a8-bdc0-5dac7433a599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3535f4cb-92ab-4e0c-af90-3163c207b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension_reduction(model: nn.Module, dataset_name) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Takes a model object and data, performs T-SNE, and returns a [DataFrame] containing \n",
    "    reduced variables and labels for each data point.\n",
    "    \n",
    "    Args:\n",
    "    - model: model object for generating features\n",
    "    - dataset_name: name of the dataset\n",
    "    Returns:\n",
    "    - pd.DataFrame: A data frame that has 'dimension 1', 'dimension 2',\n",
    "                    and 'labels' as a column\n",
    "     \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    data = load_data(device, dataset_name)\n",
    "\n",
    "    model.eval()\n",
    "    x = data.x.to(device)  # node features\n",
    "    edge_index = data.edge_index.to(device)  # graph structure\n",
    "    # use validation set for visualisation\n",
    "    x = x * data.val_mask\n",
    "    edge_index = edge_index * data.val_mask\n",
    "\n",
    "    # get node embeddings\n",
    "    with torch.no_grad():  # disable gradient calculation\n",
    "        node_embeddings = model.generate_node_embeddings(x, edge_index) # (X, A)\n",
    "\n",
    "    # dim-reduction of node embeddings with T-SNE (to 2D)\n",
    "    tsne = TSNE(n_components=2, random_state=123) \n",
    "    # need to copy Tensor to host memory first with .cpu().numpy()\n",
    "    reduced_embeddings = tsne.fit_transform(node_embeddings.cpu().numpy())\n",
    "\n",
    "    # format result df\n",
    "    reduced_df = pd.DataFrame(reduced_embeddings,\n",
    "                              columns=['dimension 1', 'dimension 2'])\n",
    "    reduced_df['labels'] = data.y.cpu().numpy()  # target labels\n",
    "\n",
    "    return reduced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09915a56-8664-448b-95fb-de9984cdc174",
   "metadata": {},
   "source": [
    "### Visualisation with scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc6cc9b-57b2-433a-819a-0f976e93985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_one(model_name, dataset_name, df) -> None:\n",
    "    \"\"\"Visualises node embeddings as a scatter plot for one model.\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    scatter = ax.scatter(df['dimension 1'], df['dimension 2'], c=df['labels'],\n",
    "                         cmap='tab10', s=10)\n",
    "    plt.colorbar(scatter, ax=ax, label='class')  # color bar for classes\n",
    "    \n",
    "    ax.set_title(f\"Visualization of node embeddings from {model_name}\",\n",
    "                 fontsize=16)\n",
    "    ax.set_xlabel(\"dimension 1\", fontsize=14)\n",
    "    ax.set_ylabel(\"dimension 2\", fontsize=14)\n",
    "\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    fig.savefig(f'{OUTPUT_DIR}{dataset_name}/{model_name}_vis.jpg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d75c5ac-c279-471f-9d56-9429e2c9b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_dimensions(models, params, layers=range(2,21,6)):\n",
    "    \"\"\"\n",
    "    Visualises dimensionality-reduced node embeddings generated by the given models.\n",
    "    - models: dictionary of (number of layers : trained model) pairs\n",
    "    - params: training parameters\n",
    "    \"\"\"\n",
    "    model_name = params['model_name']\n",
    "    dataset_name = params['dataset']\n",
    "    feature_dict = { f\"{n}_layer_{model_name}\": dimension_reduction(models[n], params) for n in layers }\n",
    "    for model, df in feature_dict.items():\n",
    "        visualise_one(model, dataset_name, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf6c6f9-e4f5-47de-adae-27e3919dfcea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
